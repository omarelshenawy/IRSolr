{
	"add": {
		"doc": {
			"id": "41b0f51f28be155cbe4deecf5296ca3fb81833c0e63d48c207441c67c46639f8",
			"url": "https://upload.wikimedia.org/math/9/5/f/95fff02452dd9ea258d284d5412a8daf.png",
				"previous": "The entropy, , of a discrete random variable is a measure of the amount of uncertainty associated with the value of .",
				"after": "(Here, is the self-information, which is the entropy contribution of an individual message, and is the expected value.) A property of entropy is that it is maximized when all the messages in the message space are equiprobable ,âi.e., most unpredictableâin which case .",
			"color": "dark|0.35713 gray|0.35713 dark|0.35713 grey|0.35713 silver|0.25093 light|0.15028 gray|0.15028 light|0.15028 grey|0.15028 gainsboro|0.11433 gray|0.039411 grey|0.039411 white|0.023637 smoke|0.023637 linen|0.012225 lavender|0.0092394 blush|0.0092394 alice|0.008974 blue|0.008974 ghost|0.0085316 white|0.0085316 sea|0.0080009 shell|0.0080009 snow|0.0075696 white|0.0048567 mint|0.0031316 cream|0.0031316  "
		}
	}
}
