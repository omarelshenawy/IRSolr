{"add":{"doc":{"id":"316b20de042261b16440b253de0a4dda0109816924092855ee787b940721fb10","url":"https://upload.wikimedia.org/wikipedia/commons/thumb/9/9e/GFO_taxonomy_tree.png/220px-GFO_taxonomy_tree.png","previous":["Human beings solve most of their problems using fast, intuitive judgements rather than the conscious, step-by-step deduction that early AI research was able to model.[43] AI has made some progress at imitating this kind of \"sub-symbolic\" problem solving: embodied agent approaches emphasize the importance of sensorimotor skills to higher reasoning; neural net research attempts to simulate the structures inside the brain that give rise to this skill; statistical approaches to AI mimic the probabilistic nature of the human ability to guess."],"after":["Knowledge representation[44] and knowledge engineering[45] are central to AI research. Many of the problems machines are expected to solve will require extensive knowledge about the world. Among the things that AI needs to represent are: objects, properties, categories and relations between objects;[46] situations, events, states and time;[47] causes and effects;[48] knowledge about knowledge (what we know about what other people know);[49] and many other, less well researched domains. A representation of \"what exists\" is an ontology: the set of objects, relations, concepts and so on that the machine knows about. The most general are called upper ontologies, which attempt to provide a foundation for all other knowledge.[50]"]}}}